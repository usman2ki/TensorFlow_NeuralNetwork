# ðŸš€ **Deep Learning Benchmark: FNN Architecture Optimization**

### ðŸ§  *TensorFlow Neural Network Benchmark: Architecture & Activation Analysis*

---

This repository presents a **comprehensive deep learning benchmark** exploring the relationship between **architecture complexity** and **predictive performance** in house price estimation using **TensorFlow/Keras**.

The project aims to **push beyond the limits** of simple hand-coded models and identify the **optimal Feedforward Neural Network (FNN)** configuration for achieving high accuracy with minimal computational overhead.

---

## ðŸŽ¯ **The Challenge: Performance vs. Simplicity**

Previous models using basic Gradient Descent failed to converge properly â€” even producing **negative (R^2)** values ðŸ˜¬.
This studyâ€™s mission was to **break that limitation** and achieve **industry-level accuracy ((R^2 > 0.8))**, using smarter architectures and activations instead of brute force.

---

## ðŸ§ª **Benchmark Grid: 54 Models Tested**

To ensure fairness, the **Adam optimizer** was held constant.
We systematically tested **54 unique FNN configurations** across a **6 Ã— 3 Ã— 3 grid**, varying activations, depth, and width.

| **Factor**     | **Test Cases**                          | **Optimal Configuration** |
| -------------- | --------------------------------------- | ------------------------- |
| **Activation** | LeakyReLU, ReLU, GELU, Swish, ELU, SELU | ðŸ† **LeakyReLU**          |
| **Depth**      | 1, 2, 3 hidden layers                   | ðŸ—ï¸ **3 Layers**          |
| **Width**      | 8, 16, 32 neurons per layer             | âš™ï¸ **32 Neurons**         |

---

## ðŸ¥‡ **Key Findings: Convergence Achieved ðŸ“ˆ**

After extensive testing, the benchmark successfully identified the **optimal FNN structure** that achieved stable convergence and superior accuracy.

| **Metric**                 | **Finding**                     | **Result**                                                     |
| -------------------------- | ------------------------------- | -------------------------------------------------------------- |
| **Overall Best Model**     | 3 Layers, 32 Neurons, LeakyReLU | ðŸ’¡ **(R^2 = 0.835)** *(Highly Accurate)*                       |
| **Convergence Comparison** | Keras (A3) vs NumPy (A2)        | âœ… **Keras: 0.835**, âŒ NumPy: -4.87                             |
| **Error Reduction**        | MSE (Keras vs NumPy)            | ðŸ”½ **35Ã— lower error with Keras**                              |
| **Conclusion**             | Adam + Early Stopping           | ðŸ§© *Essential for optimal convergence even in simple datasets* |

---

## ðŸ“‚ **Repository Contents**

| **File / Folder**                      | **Description**                                                |
| -------------------------------------- | -------------------------------------------------------------- |
| ðŸ§© `Feedforward_NeuralNetwork_Code.py` | Core engine that executes the entire 54-model benchmark.       |
| ðŸ“Š `feedforward_benchmark_results.csv` | Raw output of all 54 runs â€” configs, MSE, (R^2), runtime, etc. |
| ðŸ“ˆ `figures/`                          | Heatmaps, bar charts, and loss curves for visual analysis.     |
| ðŸ  `house_prices_dataset.csv`          | The standardized dataset used for all experiments.             |

---

## âš™ï¸ **Getting Started**

### ðŸ”— Clone the Repository

```bash
git clone https://github.com/usman2ki/TensorFlow_Benchmark_NeuralNetwork.git
```

### ðŸ§° Install Dependencies

Ensure you have the following packages installed:

```bash
pip install tensorflow keras numpy scikit-learn matplotlib
```

### â–¶ï¸ Run the Benchmark

Execute the main benchmark script:

```bash
python Feedforward_NeuralNetwork_Code.py
```

This will reproduce all 54 model runs and generate:

* Evaluation metrics (MSE, (R^2))
* Heatmaps & plots inside `/figures`
* Full log file: `feedforward_benchmark_results.csv`

---

## ðŸ§© **Highlights**

* âœ… 54 Model Experiments
* âš™ï¸ Automated Architecture Search
* ðŸ§  LeakyReLU Dominance Verified
* ðŸ“‰ 35Ã— MSE Improvement
* ðŸ“ˆ Achieved (R^2 = 0.835)

---

> ðŸ’¬ *â€œEven simple datasets deserve sophisticated engineering.â€*
> â€” *Muhammad Usman*

---
